{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Serialising a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T02:55:25.086213Z",
     "start_time": "2020-02-16T02:55:23.758762Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T03:01:00.686674Z",
     "start_time": "2020-02-16T03:01:00.668178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.863149</td>\n",
       "      <td>0.314732</td>\n",
       "      <td>0.669747</td>\n",
       "      <td>0.702656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.546542</td>\n",
       "      <td>0.563607</td>\n",
       "      <td>0.780532</td>\n",
       "      <td>0.312281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.024058</td>\n",
       "      <td>0.473108</td>\n",
       "      <td>0.447980</td>\n",
       "      <td>0.811878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.888702</td>\n",
       "      <td>0.392524</td>\n",
       "      <td>0.830159</td>\n",
       "      <td>0.452014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.266793</td>\n",
       "      <td>0.449780</td>\n",
       "      <td>0.589546</td>\n",
       "      <td>0.882689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "0  0.863149  0.314732  0.669747  0.702656\n",
       "1  0.546542  0.563607  0.780532  0.312281\n",
       "2  0.024058  0.473108  0.447980  0.811878\n",
       "3  0.888702  0.392524  0.830159  0.452014\n",
       "4  0.266793  0.449780  0.589546  0.882689"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets make a new dataframe and save it out using various formats\n",
    "df = pd.DataFrame(np.random.random(size=(100000, 4)), columns=[\"A\", \"B\", \"C\", \"D\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T03:03:34.987813Z",
     "start_time": "2020-02-16T03:03:34.219248Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"save.csv\", index=False, float_format=\"%0.3f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T03:04:00.092272Z",
     "start_time": "2020-02-16T03:04:00.079738Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_pickle(\"save.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T03:06:06.874338Z",
     "start_time": "2020-02-16T03:06:05.955905Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install tables\n",
    "df.to_hdf(\"save.hdf\", key=\"data\", format=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T03:06:56.305779Z",
     "start_time": "2020-02-16T03:06:56.204901Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install feather-format\n",
    "df.to_feather(\"save.fth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T03:10:46.080056Z",
     "start_time": "2020-02-16T03:10:46.075636Z"
    }
   },
   "outputs": [],
   "source": [
    "# If you want to get the timings you can see in the video, you'll need this extension:\n",
    "# https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/execute_time/readme.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is a very easy test - its only numeric data. If we add strings and categorical data things can slow down a lot! Let's try this on mixed Astronaut data from Kaggle: https://www.kaggle.com/nasa/astronaut-yearbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T03:14:16.764994Z",
     "start_time": "2020-02-16T03:14:16.741456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Group</th>\n",
       "      <th>Status</th>\n",
       "      <th>Birth Date</th>\n",
       "      <th>Birth Place</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Alma Mater</th>\n",
       "      <th>Undergraduate Major</th>\n",
       "      <th>Graduate Major</th>\n",
       "      <th>Military Rank</th>\n",
       "      <th>Military Branch</th>\n",
       "      <th>Space Flights</th>\n",
       "      <th>Space Flight (hr)</th>\n",
       "      <th>Space Walks</th>\n",
       "      <th>Space Walks (hr)</th>\n",
       "      <th>Missions</th>\n",
       "      <th>Death Date</th>\n",
       "      <th>Death Mission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Joseph M. Acaba</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>5/17/1967</td>\n",
       "      <td>Inglewood, CA</td>\n",
       "      <td>Male</td>\n",
       "      <td>University of California-Santa Barbara; Univer...</td>\n",
       "      <td>Geology</td>\n",
       "      <td>Geology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3307</td>\n",
       "      <td>2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>STS-119 (Discovery), ISS-31/32 (Soyuz)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Loren W. Acton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Retired</td>\n",
       "      <td>3/7/1936</td>\n",
       "      <td>Lewiston, MT</td>\n",
       "      <td>Male</td>\n",
       "      <td>Montana State University; University of Colorado</td>\n",
       "      <td>Engineering Physics</td>\n",
       "      <td>Solar Physics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STS 51-F (Challenger)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>James C. Adamson</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>3/3/1946</td>\n",
       "      <td>Warsaw, NY</td>\n",
       "      <td>Male</td>\n",
       "      <td>US Military Academy; Princeton University</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Aerospace Engineering</td>\n",
       "      <td>Colonel</td>\n",
       "      <td>US Army (Retired)</td>\n",
       "      <td>2</td>\n",
       "      <td>334</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STS-28 (Columbia), STS-43 (Atlantis)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Thomas D. Akers</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>5/20/1951</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>Male</td>\n",
       "      <td>University of Missouri-Rolla</td>\n",
       "      <td>Applied Mathematics</td>\n",
       "      <td>Applied Mathematics</td>\n",
       "      <td>Colonel</td>\n",
       "      <td>US Air Force (Retired)</td>\n",
       "      <td>4</td>\n",
       "      <td>814</td>\n",
       "      <td>4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>STS-41 (Discovery), STS-49 (Endeavor), STS-61 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Buzz Aldrin</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>1/20/1930</td>\n",
       "      <td>Montclair, NJ</td>\n",
       "      <td>Male</td>\n",
       "      <td>US Military Academy; MIT</td>\n",
       "      <td>Mechanical Engineering</td>\n",
       "      <td>Astronautics</td>\n",
       "      <td>Colonel</td>\n",
       "      <td>US Air Force (Retired)</td>\n",
       "      <td>2</td>\n",
       "      <td>289</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Gemini 12, Apollo 11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name    Year  Group   Status Birth Date    Birth Place Gender  \\\n",
       "0   Joseph M. Acaba  2004.0   19.0   Active  5/17/1967  Inglewood, CA   Male   \n",
       "1    Loren W. Acton     NaN    NaN  Retired   3/7/1936   Lewiston, MT   Male   \n",
       "2  James C. Adamson  1984.0   10.0  Retired   3/3/1946     Warsaw, NY   Male   \n",
       "3   Thomas D. Akers  1987.0   12.0  Retired  5/20/1951  St. Louis, MO   Male   \n",
       "4       Buzz Aldrin  1963.0    3.0  Retired  1/20/1930  Montclair, NJ   Male   \n",
       "\n",
       "                                          Alma Mater     Undergraduate Major  \\\n",
       "0  University of California-Santa Barbara; Univer...                 Geology   \n",
       "1   Montana State University; University of Colorado     Engineering Physics   \n",
       "2          US Military Academy; Princeton University             Engineering   \n",
       "3                       University of Missouri-Rolla     Applied Mathematics   \n",
       "4                           US Military Academy; MIT  Mechanical Engineering   \n",
       "\n",
       "          Graduate Major Military Rank         Military Branch  Space Flights  \\\n",
       "0                Geology           NaN                     NaN              2   \n",
       "1          Solar Physics           NaN                     NaN              1   \n",
       "2  Aerospace Engineering       Colonel       US Army (Retired)              2   \n",
       "3    Applied Mathematics       Colonel  US Air Force (Retired)              4   \n",
       "4           Astronautics       Colonel  US Air Force (Retired)              2   \n",
       "\n",
       "   Space Flight (hr)  Space Walks  Space Walks (hr)  \\\n",
       "0               3307            2              13.0   \n",
       "1                190            0               0.0   \n",
       "2                334            0               0.0   \n",
       "3                814            4              29.0   \n",
       "4                289            2               8.0   \n",
       "\n",
       "                                            Missions Death Date Death Mission  \n",
       "0             STS-119 (Discovery), ISS-31/32 (Soyuz)        NaN           NaN  \n",
       "1                              STS 51-F (Challenger)        NaN           NaN  \n",
       "2               STS-28 (Columbia), STS-43 (Atlantis)        NaN           NaN  \n",
       "3  STS-41 (Discovery), STS-49 (Endeavor), STS-61 ...        NaN           NaN  \n",
       "4                               Gemini 12, Apollo 11        NaN           NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"astronauts.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T03:14:48.250858Z",
     "start_time": "2020-02-16T03:14:48.237441Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"save.csv\", index=False, float_format=\"%0.4f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T03:14:52.892116Z",
     "start_time": "2020-02-16T03:14:52.876108Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"save.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T03:15:12.997156Z",
     "start_time": "2020-02-16T03:15:12.988669Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_pickle(\"save.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T03:15:16.375064Z",
     "start_time": "2020-02-16T03:15:16.365034Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_pickle(\"save.pkl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T03:19:15.617617Z",
     "start_time": "2020-02-16T03:19:15.588076Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_hdf(\"save.hdf\", key=\"data\", format=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T03:15:35.323031Z",
     "start_time": "2020-02-16T03:15:35.301528Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_hdf(\"save.hdf\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T03:15:47.513253Z",
     "start_time": "2020-02-16T03:15:47.499922Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-6e39ea4ecb2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_feather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"save.fth\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_feather\u001b[1;34m(self, fname)\u001b[0m\n\u001b[0;32m   2135\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeather_format\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_feather\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2137\u001b[1;33m         \u001b[0mto_feather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2139\u001b[0m     def to_parquet(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\feather_format.py\u001b[0m in \u001b[0;36mto_feather\u001b[1;34m(df, path)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \"\"\"\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pyarrow\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mpyarrow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeather\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, raise_on_missing, on_version)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraise_on_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow."
     ]
    }
   ],
   "source": [
    "df.to_feather(\"save.fth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T03:15:50.574863Z",
     "start_time": "2020-02-16T03:15:50.557141Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_feather(\"save.fth\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T03:20:03.082982Z",
     "start_time": "2020-02-16T03:20:03.062532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive G is HDD Storge 2\n",
      " Volume Serial Number is D2CA-B02B\n",
      "\n",
      " Directory of G:\\Qaurter2Notebooks\\piaic_q2_class_reseouces\\practiceResource\n",
      "\n",
      "01/10/2021  12:15 PM    <DIR>          .\n",
      "01/10/2021  12:15 PM    <DIR>          ..\n",
      "01/10/2021  12:12 PM    <DIR>          .ipynb_checkpoints\n",
      "01/09/2021  10:33 AM            15,377 Answers.ipynb\n",
      "01/10/2021  12:03 PM            81,593 astronauts.csv\n",
      "01/10/2021  12:10 PM            33,930 dataInspecting.ipynb\n",
      "01/10/2021  12:04 PM            19,860 dataloading.ipynb\n",
      "01/10/2021  12:14 PM            18,591 dataSavingAndSerialising.ipynb\n",
      "01/10/2021  11:57 AM            11,328 heart.csv\n",
      "01/09/2021  10:31 AM            35,216 heart.pkl\n",
      "01/09/2021  10:53 AM            32,414 NumpyVPandas.ipynb\n",
      "01/09/2021  10:33 AM             2,812 Questions.ipynb\n",
      "01/10/2021  12:14 PM            87,030 save.csv\n",
      "01/10/2021  12:15 PM           801,617 save.hdf\n",
      "01/10/2021  12:15 PM            90,693 save.pkl\n",
      "01/09/2021  10:30 AM            18,594 SavingAndSerialising.ipynb\n",
      "              13 File(s)      1,249,055 bytes\n",
      "               3 Dir(s)  391,598,575,616 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "\n",
    "In terms of file size, HDF5 is the largest for this example. Everything else is approximately equal. For small data sizes, often csv is the easiest as its human readable. HDF5 is great for *loading* in huge amounts of data quickly. Pickle is faster than CSV, but not human readable.\n",
    "\n",
    "Lots of options, don't get hung up on any of them. csv and pickle are easy and for most cases work fine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
